{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxh/cb6/GxBhhMxFrsk6bz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElayatNisrine/Front-End-Checklist/blob/master/student%20performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn openpyxl tensorflow matplotlib seaborn"
      ],
      "metadata": {
        "id": "KH-ttk-KQTst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "id": "dhELMqP3XH2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, MultiHeadAttention, LayerNormalization\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import shap\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBx5uVrzIUvX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8gVXcaUcIA8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJBWT1yRO1Jy"
      },
      "outputs": [],
      "source": [
        "# Load dataset from Google Drive\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Datasets/final dataset.csv\")\n",
        "print(df[\"Course Progress\"].dtype)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Convert time-based features (HH:MM:SS) into total minutes\n",
        "def convert_time_to_minutes(time_str):\n",
        "    if isinstance(time_str, str):\n",
        "        h, m, s = map(int, time_str.split(':'))\n",
        "        return h * 60 + m + s / 60\n",
        "    return 0  # Handle missing values\n",
        "\n",
        "df[\"Course Time Spent\"] = df[\"Course Time Spent\"].apply(convert_time_to_minutes)\n",
        "#df[\"Lesson Time Spent\"] = df[\"Lesson Time Spent\"].apply(convert_time_to_minutes)\n",
        "\n",
        "# ðŸ“Œ Convert Progress from % to Numeric (remove % and convert to float)\n",
        "df[\"Course Progress\"] = df[\"Course Progress\"].str.replace(\"%\", \"\").astype(float) / 100\n",
        "#df[\"Lesson Progress\"] = df[\"Lesson Progress\"].str.replace(\"%\", \"\").astype(float) / 100  # Scale to 0-1\n",
        "\n",
        "# ðŸ“Œ Convert test scores (e.g., \"122/400\") into numeric values\n",
        "def extract_score(score_str):\n",
        "    if isinstance(score_str, str):\n",
        "        return int(score_str.split('/')[0])  # Extract only the actual score\n",
        "    return 0  # Handle missing values\n",
        "\n",
        "df[\"First Test Score\"] = df[\"First Test Score\"].apply(extract_score)\n",
        "df[\"Last Test Score\"] = df[\"Last Test Score\"].apply(extract_score)\n",
        " # Adjusted for consistency\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "o9b2svkJidKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ðŸ“Œ Count the number of activities per student-language pair\n",
        "df[\"Activity Count\"] = 1  # Each row represents an activity\n",
        "\n",
        "# ðŸ“Œ Aggregate data per student-language (NOT per course)\n",
        "student_df = df.groupby([\"Email\", \"Language of Study\"]).agg({\n",
        "    \"Course Time Spent\": \"sum\",  # Total learning time in minutes\n",
        "    \"Course Progress\": \"mean\",   # Average progress across courses\n",
        "    \"First Test Score\": \"first\", # Keep the first test score (Initial Level)\n",
        "    \"Last Test Score\": \"first\", # Keep the final test score (Target Variable)\n",
        "    \"Activity Count\": \"count\"    # Count total activities per student-language\n",
        "}).reset_index()\n",
        "# Count number of rows per student-language before aggregation\n",
        "activity_check = df.groupby([\"Email\", \"Language of Study\"]).size().reset_index(name=\"Actual Activity Count\")\n",
        "\n",
        "# Display the first few rows\n",
        "print(activity_check.head(10))\n",
        "# ðŸ“Œ Encode \"Language of Study\" (Convert categorical values to numeric)\n",
        "encoder = LabelEncoder()\n",
        "student_df[\"Language of Study\"] = encoder.fit_transform(student_df[\"Language of Study\"])\n",
        "\n",
        "# ðŸ“Œ Select features for deep learning\n",
        "features = [\"Language of Study\", \"Course Time Spent\", \"Course Progress\", \"First Test Score\"]\n",
        "target = [\"Last Test Score\"]\n",
        "\n",
        "# ðŸ“Œ Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "student_df[features] = scaler.fit_transform(student_df[features])\n",
        "student_df[target] = scaler.fit_transform(student_df[target])\n",
        "\n",
        "# ðŸ“Œ Reshape for LSTM (samples, time steps, features)\n",
        "X = student_df[features].values.reshape(student_df.shape[0], 1, len(features))\n",
        "y = student_df[target].values\n",
        "\n",
        "# ðŸ“Œ Split dataset into train (80%) and test (20%)\n",
        "split = int(0.8 * len(student_df))\n",
        "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
        "\n",
        "\n",
        "print(student_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aptXTVz6LT8W",
        "outputId": "48633f83-4e00-4300-a09f-2a7907de99fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Email   Language of Study  \\\n",
            "0          abbadi.maroua@etu.uae.ac.ma  English (American)   \n",
            "1          abbadi.maroua@etu.uae.ac.ma              French   \n",
            "2    abdallahzayd.drissi@etu.uae.ac.ma   English (British)   \n",
            "3    abdallahzayd.drissi@etu.uae.ac.ma              French   \n",
            "4  abdelali.hourmatallah@etu.uae.ac.ma  English (American)   \n",
            "5  abdelali.hourmatallah@etu.uae.ac.ma              French   \n",
            "6     abdelhakim.aourfat@etu.uae.ac.ma  English (American)   \n",
            "7     abdelhakim.aourfat@etu.uae.ac.ma              French   \n",
            "8    abdeljalil.serrakhi@etu.uae.ac.ma  English (American)   \n",
            "9    abdeljalil.serrakhi@etu.uae.ac.ma              French   \n",
            "\n",
            "   Actual Activity Count  \n",
            "0                     50  \n",
            "1                     17  \n",
            "2                     25  \n",
            "3                      1  \n",
            "4                     65  \n",
            "5                     68  \n",
            "6                     45  \n",
            "7                     14  \n",
            "8                     97  \n",
            "9                     36  \n",
            "                                 Email  Language of Study  Course Time Spent  \\\n",
            "0          abbadi.maroua@etu.uae.ac.ma               0.00           0.284438   \n",
            "1          abbadi.maroua@etu.uae.ac.ma               0.50           0.181528   \n",
            "2    abdallahzayd.drissi@etu.uae.ac.ma               0.25           0.145503   \n",
            "3    abdallahzayd.drissi@etu.uae.ac.ma               0.50           0.000493   \n",
            "4  abdelali.hourmatallah@etu.uae.ac.ma               0.00           0.278104   \n",
            "5  abdelali.hourmatallah@etu.uae.ac.ma               0.50           0.132646   \n",
            "6     abdelhakim.aourfat@etu.uae.ac.ma               0.00           0.204343   \n",
            "7     abdelhakim.aourfat@etu.uae.ac.ma               0.50           0.017756   \n",
            "8    abdeljalil.serrakhi@etu.uae.ac.ma               0.00           0.316258   \n",
            "9    abdeljalil.serrakhi@etu.uae.ac.ma               0.50           0.117777   \n",
            "\n",
            "   Course Progress  First Test Score  Last Test Score  Activity Count  \n",
            "0         0.884600          0.702778         0.722222              50  \n",
            "1         0.722941          0.616667         0.794444              17  \n",
            "2         0.870400          0.513889         0.511111              25  \n",
            "3         0.060000          0.697222         0.619444               1  \n",
            "4         0.967077          0.502778         0.394444              65  \n",
            "5         0.911618          0.552778         0.547222              68  \n",
            "6         0.961111          0.666667         0.600000              45  \n",
            "7         0.295000          0.536111         0.475000              14  \n",
            "8         0.868866          0.433333         0.522222              97  \n",
            "9         0.853333          0.544444         0.563889              36  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Define LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(1, len(features))),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output: Final Test Score Prediction\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# ðŸ“Œ Train LSTM model and record time\n",
        "start_time = time.time()\n",
        "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "# Save the trained model (optional)\n",
        "lstm_model.save(\"trained_lstm_model.h5\")\n",
        "lstm_time = time.time() - start_time\n",
        "\n",
        "# ðŸ“Œ Predict using LSTM\n",
        "y_pred_lstm = lstm_model.predict(X_test)\n",
        "\n",
        "# ðŸ“Œ Convert predictions back to original scale\n",
        "y_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
        "y_actual = scaler.inverse_transform(y_test)\n",
        "\n",
        "# ðŸ“Œ Evaluate LSTM model\n",
        "lstm_mae = mean_absolute_error(y_actual, y_pred_lstm)\n",
        "lstm_mse = mean_squared_error(y_actual, y_pred_lstm)  # This returns MSE\n",
        "lstm_rmse = np.sqrt(lstm_mse)\n",
        "print(f\"LSTM Model - MAE: {lstm_mae:.2f}, RMSE: {lstm_rmse:.2f}, Training Time: {lstm_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "# ðŸ“Œ Disable eager execution to avoid SHAP gradient errors\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# ðŸ“Œ Load the trained model\n",
        "lstm_model = load_model(\"trained_lstm_model.h5\")\n",
        "\n",
        "# ðŸ“Œ Create SHAP DeepExplainer\n",
        "explainer = shap.DeepExplainer(lstm_model, X_train)\n",
        "\n",
        "# ðŸ“Œ Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# ðŸ“Œ Plot SHAP summary\n",
        "shap.summary_plot(shap_values, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "9El3JpjFMKaU",
        "outputId": "255549e5-f6ea-4586-bb95-3320aa41e9be"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "gradient registry has no entry for: shap_DivNoNan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-13defc5ece01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ðŸ“Œ Train LSTM model and record time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# Save the trained model (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_lstm_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: gradient registry has no entry for: shap_DivNoNan"
          ]
        }
      ]
    }
  ]
}